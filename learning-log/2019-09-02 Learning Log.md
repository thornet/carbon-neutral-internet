# 2019-09-02 Learning Log

Great conversation today with Kate McCurdy, a natural language processing researcher at the University of Edinburgh, about her upcoming paper on the carbon costs of AI. Some highlights: 

* Awareness is going in the AI research community about emissions. Two papers really helped spark the debate: [Energy and Policy Considerations for Deep Learning in NLP by Emma Strubell, Ananya Ganesh, Andrew McCallum](https://arxiv.org/abs/1906.02243) and [Green AI by Roy Schwartz, Jesse Dodge, Noah A. Smith, Oren Etzioni](https://www.semanticscholar.org/paper/Green-AI-Schwartz-Dodge/fb73b93de3734a996829caf31e4310e0054e9c6b).
** "The computations required for deep learning research have been doubling every few months, resulting in an estimated 300,000x increase from 2012 to 2018 [2]. These computations have a surprisingly large carbon footprint [38]. Ironically, deep learning was inspired by the human brain, which is remarkably energy efficient. Moreover, the financial cost of the computations can make it difficult for academics, students, and researchers, in particular those from emerging economies, to engage in deep learning research. This position paper advocates a practical solution by making efficiency an evaluation criterion for research alongside accuracy and related measures. In addition, we propose reporting the financial cost or "price tag" of developing, training, and running models to provide baselines for the investigation of increasingly efficient methods. Our goal is to make AI both greener and more inclusive---enabling any inspired undergraduate with a laptop to write high-quality research papers. Green AI is an emerging focus at the Allen Institute for AI" 
* The AI research community may have been slow to this conversation thanks to abstraction: carbon costs is not in the "layer" they operate in. And the costs are not directly felt. 
* Promising research into ways to simplify machine learning that will likely have energy yields, too: compressed deep learning, federated machine learning. Smaller models might also be more interpretable, too, which is another win. 
* Increasingly, more metadata is needed to understand how a model works. This increases "data exhaust" and generally requires increasing resources to maintain and keep straight. AI research sometimes accounts for the costs of creating a model, but hardly ever in its use, maintenance and end-of-life phases. Vladan Joler and Kate Crawford's [Anatomy of AI](https://anatomyof.ai/) is a great reference for how to understand the lifecycle costs. 
* Keep making the case of IoT and AI being interrelated. It's the AI that makes the "thing" smart, and often a the physical object is an entry point into an AI system (microphone, camera, sensors, etc). 
* "Fancy counting" is a fun way to describe deep learning. 
* Further recommended reading: [Machine Learning: The High Interest Credit Card of Technical Debt by D. Sculley and Gary Holt and Daniel Golovin and Eugene Davydov and Todd Phillips and Dietmar Ebner and Vinay Chaudhary and Michael Young](https://ai.google/research/pubs/pub43146) 

[Environmental full-cost accounting](https://en.wikipedia.org/wiki/Environmental_full-cost_accounting) is an established way of measuring and talking about the "true costs" of making something. 

Upcoming Berlin event: [Das Ã–ko-Institut: Transformation = [nachhaltig + digital](https://www.oeko.de/jahrestagung2019/)

Open letter to AWS is getting sharper and signatories are growing. 

[ The London College of Political Technologists

[Newspeak House is an independent residential college founded in 2015 to study, nurture and inspire emerging communities of practice across UK public sector and civil society](https://nwspk.com/) -- interesting model for learning and research. Funded by independent members. Connection via Wikimedia. 